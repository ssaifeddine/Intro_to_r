---
title: "Logistic Regression"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Logistic Regression 

In statistics, the logistic model (or logit model) is used to model the probability of a certain class or event existing such as pass/fail, win/lose, alive/dead or healthy/sick. This can be extended to model several classes of events such as determining whether an image contains a cat, dog, lion, etc. Each object being detected in the image would be assigned a probability between 0 and 1, with a sum of one.

The equation for Logistic Regression can be written as: 

$$
output = log{_e}(\frac{p}{1-p}) = \beta_0 + \beta_1 x + \beta_2 x^2 + ... + \beta_n x^n \
$$
The "output" is also called logit. 
Another name for "output" is the log odds ratio. 
p is the probability of an event occuring or not.
So the odds ratio is: (Probability of an event occurring divided by probability of an event not occurring)

$$
\frac{p}{1-p}
$$
Suppose: 
$$
\begin{aligned}
        Y = \beta_0 + \beta_1 x + \beta_2 x^2 + ... + \beta_n x^n  \\   
\end{aligned}
$$

Then

$$
log{_e}(\frac{p}{1-p}) = Y \\
$$
Taking log on both the sides 


$$
\\
\frac{p}{1-p} = e^Y \\
$$

Solving for p, we will get

$$
p = \frac{e^Y}{1+e^Y} \\
$$
As Y increases positively p approaches  1 and as Y increases negatively, then p approaches to zero


```{r read_student_admissions}
library(readr)
# Use read_csv() to read the file 
file_location <- paste0(getwd(), "/../Input/UCLA_Student_Admissions.csv")
admissions <- read_csv(file_location)
#df <- read_csv(file.choose())

```

```{r convert_to_factor}
admissions$rank <- factor(admissions$rank)

```


```{r get_a_glimpse_of_data}
library(tibble) 
glimpse(admissions)
```

```{r train_and_test_split}
# Include your code to select train and test samples 
# use the seed 100 for selecting the random samples for reproducibility 
# Use 80% of your data to create a training sample 
# Use 20% of your data to create a test sample 
admissions$sample_col <- sample(c(1,2), nrow(admissions), 
                     replace = T, prob = c(0.8, 0.2))
train <- admissions[admissions$sample_col ==1, ]
test <- admissions[admissions$sample_col == 2, ]
```

```{r glm_model}
# Include your code to run the Generalized Linear Regression (GLM) model of "binomial" family
# Print the summary of the model 
# The model returns coefficients that impact the outcome variable admit 
# Interpret the results in terms of log odds 
model <- glm(admit ~ gre+gpa+rank,
             family = "binomial",
             data = train)
summary(model)
```

```{r}
# Make predictions for the train sample
# Create a confusion matrix using the train sample and calculate the accuracy of the model using training sample  
predicted_admit <- predict(model,
                           train[-5], type = "response") #ignoring the fifth column 
head(predicted_admit)

```


```{r predicted_outcome}
predicted_admit <- ifelse(predicted_admit > 0.5, 1, 0)

```

```{r add_prediction_to_train}
train$prediction <- predicted_admit
confusionMatrix <- table(train$admit, train$prediction)
confusionMatrix <- as.data.frame(confusionMatrix)
#View(confusionMatrix)
accuracy <- sum(confusionMatrix[
  confusionMatrix$Var1 == confusionMatrix$Var2, "Freq"])/
  sum(confusionMatrix$Fre)
print(accuracy)
```


```{r}
# Make predictions for the test sample
# Create a confusion matrix using the train sample and calculate the accuracy of the model using training sample  
predicted_admit1 <- predict(model,
                           test[-5], type = "response") #ignoring the fifth column 
head(predicted_admit1)

```


```{r}
predicted_admit1 <- ifelse(predicted_admit1 > 0.5, 1, 0)
```

```{r}
test$prediction <- predicted_admit1
confusionMatrix1 <- table(test$admit, test$prediction)
confusionMatrix1 <- as.data.frame(confusionMatrix1)
#View(confusionMatrix)
accuracy <- sum(confusionMatrix1[
  confusionMatrix1$Var1 == confusionMatrix1$Var2, "Freq"])/
  sum(confusionMatrix1$Fre)
print(accuracy)
```

```{r making_interpretation}
exp(model$coefficients)

```

